{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Corresponding Recording: [Webscraping Lecture](https://vimeo.com/507104276/6ea87c957b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![soup](https://images.unsplash.com/photo-1542831371-29b0f74f9713?ixid=MXwxMjA3fDB8MHxzZWFyY2h8MXx8aHRtbHxlbnwwfHwwfA%3D%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=800&q=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda:  \n",
    "\n",
    "SWBAT:\n",
    "\n",
    "- Describe webscraping in the context of other data-gathering methods;\n",
    "- Identify the basic structure of a webpage;\n",
    "- Become familiar with the essential objects and critical methods of `BeautifulSoup`;\n",
    "- Be able to scrape data from a live website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "We have already developed many ways of interacting with data.  We are able to:\n",
    "\n",
    "* import .csv files (and other .csv-like objects)\n",
    "* gather data from API's and interact with JSON objects\n",
    "* query SQL databases\n",
    "\n",
    "There is publicly available data all over the internet ripe for scraping, whether that be artist information data from wikipedia, song lyrics from songlyrics.com, or texts of famous books from Project Gutenberg. Below, we will learn how to navigate HTML and CSS to bring data into our local computers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The components of a web page\n",
    "\n",
    "When we visit a web page, our web browser makes a GET request to a web server. The server then sends back files that tell our browser how to render the page for us. The files fall into a few main types:\n",
    "\n",
    "- HTML — contain the main content of the page.\n",
    "- CSS — add styling to make the page look nicer.\n",
    "- JS — Javascript files add interactivity to web pages.\n",
    "- Images — image formats, such as JPG and PNG allow web pages to show pictures.\n",
    "\n",
    "After our browser receives all the files, it renders the page and displays it to us. There’s a lot that happens behind the scenes to render a page nicely, but we don’t need to worry about most of it when we’re web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML\n",
    "\n",
    "\n",
    "HyperText Markup Language (HTML) is a language that web pages are created in. HTML isn’t a programming language, like Python — instead, it’s a markup language that tells a browser how to layout content. \n",
    "\n",
    "Let’s take a quick tour through HTML so we know enough to scrape effectively. HTML consists of elements called tags. The most basic tag is the `<html>` tag. This tag tells the web browser that everything inside of it is HTML. We can make a simple HTML document just using this tag:\n",
    "\n",
    "~~~\n",
    "<html>\n",
    "</html>\n",
    "~~~\n",
    "&#x2B07; Example cell with html in Markdown!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right inside an html tag, we put two other tags, the head tag, and the body tag. The main content of the web page goes into the body tag. The head tag contains data about the title of the page, and other information that generally isn’t useful in web scraping:\n",
    "\n",
    "~~~\n",
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "    </body>\n",
    "</html>\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll now add our first content to the page, in the form of the p tag. The p tag defines a paragraph, and any text inside the tag is shown as a separate paragraph:\n",
    "~~~\n",
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "          <p>\n",
    "            Here's a paragraph of text!\n",
    "        </p>\n",
    "        <p>\n",
    "            Here's a second paragraph of text!\n",
    "        </p>\n",
    "    </body>\n",
    "</html>\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "          <p>\n",
    "            Here's a paragraph of text!\n",
    "        </p>\n",
    "        <p>\n",
    "            Here's a second paragraph of text!\n",
    "        </p>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tags have commonly used names that depend on their position in relation to other tags:\n",
    "\n",
    "- **child** — a child is a tag inside another tag. So the two p tags above are both children of the body tag.\n",
    "- **parent** — a parent is the tag another tag is inside. Above, the html tag is the parent of the body tag.\n",
    "- **sibiling** — a sibiling is a tag that is nested inside the same parent as another tag. For example, head and body are siblings, since they’re both inside html. Both p tags are siblings, since they’re both inside body."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add properties to HTML tags that change their behavior:\n",
    "\n",
    "~~~\n",
    "<html>\n",
    "  <head></head>\n",
    "  <body>\n",
    "    <p>\n",
    "      Here's a paragraph of text!\n",
    "      <a href=\"https://www.dataquest.io\">Learn Data Science Online</a>\n",
    "    </p>\n",
    "    <p>\n",
    "      Here's a second paragraph of text!\n",
    "      <a href=\"https://www.python.org\">Python</a>        \n",
    "    </p>\n",
    "  </body>\n",
    "</html>\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p>\n",
    "            Here's a paragraph of text!\n",
    "            <a href=\"https://www.dataquest.io\">Learn Data Science Online</a>\n",
    "        </p>\n",
    "        <p>\n",
    "            Here's a second paragraph of text!\n",
    "            <a href=\"https://www.python.org\">Python</a>        </p>\n",
    "    </body></html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, we added two a tags. a tags are links, and tell the browser to render a link to another web page. The href property of the tag determines where the link goes.\n",
    "\n",
    "a and p are extremely common html tags. Here are a few others:\n",
    "\n",
    "- *div*: indicates a division, or area, of the page.\n",
    "- *b*: bolds any text inside.\n",
    "- *i*: italicizes any text inside.\n",
    "- *u*: underlines any text inside.\n",
    "- *table*: creates a table.\n",
    "- *form*: creates an input form.\n",
    "\n",
    "\n",
    "For a full list of tags, look [here](https://developer.mozilla.org/en-US/docs/Web/HTML/Element)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <b>bold</b> <br/>\n",
    "    <i>italics</i> <br/>\n",
    "    <u>underlining</u>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two special properties that give HTML elements names, and make them easier to interact with when we’re scraping: **class** and **id**. \n",
    "\n",
    "- One element can have multiple classes, and a class can be shared between elements. \n",
    "- Each element can only have one id, and an id can only be used once on a page. \n",
    "- Classes and ids are optional, and not all elements will have them.\n",
    "\n",
    "We can add classes and ids to our example:\n",
    "\n",
    "~~~\n",
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p class=\"bold-paragraph\">\n",
    "            Here's a paragraph of text!\n",
    "            <a href=\"https://www.dataquest.io\" id=\"learn-link\">Learn Data Science Online</a>\n",
    "        </p>\n",
    "        <p class=\"bold-paragraph extra-large\">\n",
    "            Here's a second paragraph of text!\n",
    "            <a href=\"https://www.python.org\" class=\"extra-large\">Python</a>\n",
    "        </p>\n",
    "    </body>\n",
    "</html>\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p class=\"bold-paragraph\">\n",
    "            Here's a paragraph of text!\n",
    "            <a href=\"https://www.dataquest.io\" id=\"learn-link\">Learn Data Science Online</a>\n",
    "        </p>\n",
    "        <p class=\"bold-paragraph extra-large\">\n",
    "            Here's a second paragraph of text!\n",
    "            <a href=\"https://www.python.org\" class=\"extra-large\">Python</a>\n",
    "        </p>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at a sample web page from our local computer\n",
    "- Open up example.com in your browser.\n",
    "- Open up the inspector\n",
    "    - Mac: cmd+option+c\n",
    "    - Windows: ctrl+shift+c\n",
    "- Click on the elements tab, and click on an element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a sample webpage\n",
    "\n",
    "Use [this site](https://htmledit.squarefree.com/) to see your page as you edit the underlying html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscraping with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The requests library\n",
    "The first thing we’ll need to do to scrape a web page is to download the page. We can download pages using the Python requests library (similar to interacting with APIs!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(\"http://dataquestio.github.io/web-scraping-pages/simple.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running our request, we get a Response object. This object has a status_code property, which indicates if the page was downloaded successfully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print out the HTML content of the page using the content property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <p>Here is some simple content for this page.</p>\\n    </body>\\n</html>'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing a page with BeautifulSoup\n",
    "\n",
    "We can use the BeautifulSoup library to parse this document, and extract the text from the `<p>` tag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['html',\n",
       " <html>\n",
       " <head>\n",
       " <title>A simple example page</title>\n",
       " </head>\n",
       " <body>\n",
       " <p>Here is some simple content for this page.</p>\n",
       " </body>\n",
       " </html>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(req.content)\n",
    "list(soup.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   A simple example page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p>\n",
      "   Here is some simple content for this page.\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all the tags are nested, we can move through the structure one level at a time. We can first select all the elements at the top level of the page using the `children` property of `soup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['html',\n",
       " <html>\n",
       " <head>\n",
       " <title>A simple example page</title>\n",
       " </head>\n",
       " <body>\n",
       " <p>Here is some simple content for this page.</p>\n",
       " </body>\n",
       " </html>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(soup.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[bs4.element.Doctype, bs4.element.Tag]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(item) for item in list(soup.children)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Tag` object allows us to navigate through an HTML document, and extract other tags and text. You can learn more about the various `BeautifulSoup` objects [here](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#kinds-of-objects).\n",
    "\n",
    "We can now select the html tag and its children by taking the second item in the list:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<p>Here is some simple content for this page.</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = list(soup.children)[1]\n",
    "html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item in the list returned by the `children` property is also a `BeautifulSoup` object, so we can also call the `children` method on `html`.\n",
    "\n",
    "Now we can find the `children` inside the `html` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " <head>\n",
       " <title>A simple example page</title>\n",
       " </head>,\n",
       " '\\n',\n",
       " <body>\n",
       " <p>Here is some simple content for this page.</p>\n",
       " </body>,\n",
       " '\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(html.children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, there are two tags here, `head`, and `body`. We want to extract the text inside the `p` tag, so we’ll dive into the body:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = list(html.children)[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now isolate the `p` tag:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = list(body.children)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we’ve isolated the tag, we can use the `get_text` method to extract all of the text inside the tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tag.get_text of <p>Here is some simple content for this page.</p>>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.get_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding all instances of a tag at once\n",
    "\n",
    "If we want to extract a single tag, we can instead use the find_all method, which will find all the instances of a tag on a page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>Here is some simple content for this page.</p>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(req.content)\n",
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `find_all` returns a list, so we’ll have to loop through, or use list indexing, it to extract text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is some simple content for this page.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p')[0].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you instead only want to find the first instance of a tag, you can use the `find` method, which will return a single `BeautifulSoup` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>Here is some simple content for this page.</p>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for tags by class and id\n",
    "\n",
    "\n",
    "We introduced classes and ids earlier, but it probably wasn’t clear why they were useful. Classes and ids are used by CSS to determine which HTML elements to apply certain styles to. We can also use them when scraping to specify specific elements we want to scrape. Let's look at the following page:\n",
    "\n",
    "~~~\n",
    "<html>\n",
    "    <head>\n",
    "        <title>A simple example page</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div>\n",
    "            <p class=\"inner-text first-item\" id=\"first\">\n",
    "                First paragraph.\n",
    "            </p>\n",
    "            <p class=\"inner-text\">\n",
    "                Second paragraph.\n",
    "            </p>\n",
    "        </div>\n",
    "        <p class=\"outer-text first-item\" id=\"second\">\n",
    "            <b>\n",
    "                First outer paragraph.\n",
    "            </b>\n",
    "        </p>\n",
    "        <p class=\"outer-text\">\n",
    "            <b>\n",
    "                Second outer paragraph.\n",
    "            </b>\n",
    "        </p>\n",
    "    </body>\n",
    "</html>\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                First paragraph.\n",
       "            </p>\n",
       "<p class=\"inner-text\">\n",
       "                Second paragraph.\n",
       "            </p>\n",
       "</div>\n",
       "<p class=\"outer-text first-item\" id=\"second\">\n",
       "<b>\n",
       "                First outer paragraph.\n",
       "            </b>\n",
       "</p>\n",
       "<p class=\"outer-text\">\n",
       "<b>\n",
       "                Second outer paragraph.\n",
       "            </b>\n",
       "</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html\")\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the `find_all` method to search for items by class or by id. In the below example, we’ll search for any `p` tag that has the class `outer-text`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>,\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p', class_='outer-text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below example, we’ll look for any tag that has the class `outer-text`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"outer-text first-item\" id=\"second\">\n",
       "<b>\n",
       "                First outer paragraph.\n",
       "            </b>\n",
       "</p>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(class_=\"outer-text\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also search for elements by `id`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(id=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More sophisticated webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://forecast.weather.gov/MapClick.php?lat=41.8843&lon=-87.6324#.XdPlJUVKg6g'\n",
    "request = requests.get(url)\n",
    "soup = BeautifulSoup(request.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"period-name\">This<br/>Afternoon</p>,\n",
       " <p class=\"period-name\">Tonight<br/><br/></p>,\n",
       " <p class=\"period-name\">Friday<br/><br/></p>,\n",
       " <p class=\"period-name\">Friday<br/>Night</p>,\n",
       " <p class=\"period-name\">Saturday<br/><br/></p>,\n",
       " <p class=\"period-name\">Saturday<br/>Night</p>,\n",
       " <p class=\"period-name\">Sunday<br/><br/></p>,\n",
       " <p class=\"period-name\">Sunday<br/>Night</p>,\n",
       " <p class=\"period-name\">Monday<br/><br/></p>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = soup.find_all(class_='period-name')\n",
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"short-desc\">Sunny and<br/>Breezy</p>,\n",
       " <p class=\"short-desc\">Mostly Clear</p>,\n",
       " <p class=\"short-desc\">Mostly Sunny</p>,\n",
       " <p class=\"short-desc\">Mostly Cloudy</p>,\n",
       " <p class=\"short-desc\">Mostly Sunny</p>,\n",
       " <p class=\"short-desc\">Mostly Cloudy</p>,\n",
       " <p class=\"short-desc\">Mostly Cloudy</p>,\n",
       " <p class=\"short-desc\">Breezy.<br/>Mostly Cloudy<br/>then Slight<br/>Chance<br/>Rain/Snow</p>,\n",
       " <p class=\"short-desc\">Breezy.<br/>Chance<br/>Rain/Snow<br/>then Rain<br/>Likely</p>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descs = soup.find_all(class_='short-desc')\n",
    "descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ThisAfternoon', 'Sunny andBreezy'),\n",
       " ('Tonight', 'Mostly Clear'),\n",
       " ('Friday', 'Mostly Sunny'),\n",
       " ('FridayNight', 'Mostly Cloudy'),\n",
       " ('Saturday', 'Mostly Sunny'),\n",
       " ('SaturdayNight', 'Mostly Cloudy'),\n",
       " ('Sunday', 'Mostly Cloudy'),\n",
       " ('SundayNight', 'Breezy.Mostly Cloudythen SlightChanceRain/Snow'),\n",
       " ('Monday', 'Breezy.ChanceRain/Snowthen RainLikely')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "together = [(entry[0].text, entry[1].text) for entry in zip(times, descs)]\n",
    "together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling in a Table\n",
    "\n",
    "*In general you'll need to examine the html code so that you can tell the BeautifulSoup parser what to look for!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.pro-football-reference.com/'\n",
    "\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbodies = soup.find_all('tbody')\n",
    "len(tbodies )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'BUF*', 'wins': '13', 'losses': '3', 'ties': '0'},\n",
       " {'name': 'MIA', 'wins': '10', 'losses': '6', 'ties': '0'},\n",
       " {'name': 'NWE', 'wins': '7', 'losses': '9', 'ties': '0'},\n",
       " {'name': 'NYJ', 'wins': '2', 'losses': '14', 'ties': '0'},\n",
       " {'name': 'PIT*', 'wins': '12', 'losses': '4', 'ties': '0'},\n",
       " {'name': 'BAL+', 'wins': '11', 'losses': '5', 'ties': '0'},\n",
       " {'name': 'CLE+', 'wins': '11', 'losses': '5', 'ties': '0'},\n",
       " {'name': 'CIN', 'wins': '4', 'losses': '11', 'ties': '1'},\n",
       " {'name': 'TEN*', 'wins': '11', 'losses': '5', 'ties': '0'},\n",
       " {'name': 'IND+', 'wins': '11', 'losses': '5', 'ties': '0'},\n",
       " {'name': 'HOU', 'wins': '4', 'losses': '12', 'ties': '0'},\n",
       " {'name': 'JAX', 'wins': '1', 'losses': '15', 'ties': '0'},\n",
       " {'name': 'KAN*', 'wins': '14', 'losses': '2', 'ties': '0'},\n",
       " {'name': 'LVR', 'wins': '8', 'losses': '8', 'ties': '0'},\n",
       " {'name': 'LAC', 'wins': '7', 'losses': '9', 'ties': '0'},\n",
       " {'name': 'DEN', 'wins': '5', 'losses': '11', 'ties': '0'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams = []\n",
    "table = soup.find('table', {'id': 'AFC'})\n",
    "\n",
    "for row in table.find('tbody').find_all('tr'):\n",
    "    try:\n",
    "        team = {'name': row.find('th', {'data-stat': 'team'}).text,\n",
    "               'wins': row.find('td', {'data-stat': 'wins'}).text,\n",
    "               'losses': row.find('td', {'data-stat': 'losses'}).text,\n",
    "               'ties': row.find('td', {'data-stat': 'ties'}).text}\n",
    "        teams.append(team)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining our data into a Pandas DataFrame\n",
    "\n",
    "We can now combine the data into a Pandas DataFrame and analyze it.\n",
    "\n",
    "In order to do this, we’ll call the DataFrame class, and pass in each list of items that we have. We pass them in as part of a dictionary. Each dictionary key will become a column in the DataFrame, and each list will become the values in the column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>ties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BUF*</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MIA</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NWE</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NYJ</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIT*</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BAL+</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CLE+</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CIN</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TEN*</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IND+</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HOU</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>JAX</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KAN*</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LVR</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LAC</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DEN</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name wins losses ties\n",
       "0   BUF*   13      3    0\n",
       "1    MIA   10      6    0\n",
       "2    NWE    7      9    0\n",
       "3    NYJ    2     14    0\n",
       "4   PIT*   12      4    0\n",
       "5   BAL+   11      5    0\n",
       "6   CLE+   11      5    0\n",
       "7    CIN    4     11    1\n",
       "8   TEN*   11      5    0\n",
       "9   IND+   11      5    0\n",
       "10   HOU    4     12    0\n",
       "11   JAX    1     15    0\n",
       "12  KAN*   14      2    0\n",
       "13   LVR    8      8    0\n",
       "14   LAC    7      9    0\n",
       "15   DEN    5     11    0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Football data from the table in dictionary form (very easy!)\n",
    "\n",
    "football = pd.DataFrame(teams)\n",
    "football"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ThisAfternoon</td>\n",
       "      <td>Sunny andBreezy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tonight</td>\n",
       "      <td>Mostly Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Mostly Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FridayNight</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>Mostly Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SaturdayNight</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SundayNight</td>\n",
       "      <td>Breezy.Mostly Cloudythen SlightChanceRain/Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Breezy.ChanceRain/Snowthen RainLikely</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time                                     description\n",
       "0  ThisAfternoon                                 Sunny andBreezy\n",
       "1        Tonight                                    Mostly Clear\n",
       "2         Friday                                    Mostly Sunny\n",
       "3    FridayNight                                   Mostly Cloudy\n",
       "4       Saturday                                    Mostly Sunny\n",
       "5  SaturdayNight                                   Mostly Cloudy\n",
       "6         Sunday                                   Mostly Cloudy\n",
       "7    SundayNight  Breezy.Mostly Cloudythen SlightChanceRain/Snow\n",
       "8         Monday           Breezy.ChanceRain/Snowthen RainLikely"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weather data from the list of doubles\n",
    "\n",
    "weather = pd.DataFrame(together,\n",
    "                      columns=['time', 'description'])\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
